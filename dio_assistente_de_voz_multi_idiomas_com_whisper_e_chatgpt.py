# -*- coding: utf-8 -*-
"""DIO - Assistente de Voz Multi-Idiomas Com Whisper e ChatGPT

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kt0JsVVuQs3Ta4wAOpTaSlxMP6CJAt0z
"""

language = 'pt'

"""# 1. Grava칞칚o de 츼udio Com Python (e Uma Pitada de JavaScript) 游꿗"""

# Refer칡ncia: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be

from IPython.display import Audio, display, Javascript
from google.colab import output
from base64 import b64decode

# C칩digo JavaScript para gravar 치udio do usu치rio usando a "MediaStream Recording API"
RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=5):
  # Executa o c칩digo JavaScript para gravar o 치udio
  display(Javascript(RECORD))
  # Recebe o 치udio gravado como resultado do JavaScript
  js_result = output.eval_js('record(%s)' % (sec * 1000))
   # Decodifica o 치udio em base64
  audio = b64decode(js_result.split(',')[1])
  # Salva o 치udio em um arquivo
  file_name = 'request_audio.wav'
  with open(file_name, 'wb') as f:
    f.write(audio)
  # Retorna o caminho do arquivo de 치udio (pasta padr칚o do Google Colab)
  return f'/content/{file_name}'

# Grava o 치udio do usu치rio por um tempo determinado (padr칚o 5 segundos)
print('Ouvindo...\n')
record_file = record()

# Exibe o 치udio gravado
display(Audio(record_file, autoplay=False))

"""# 2. Reconhecimento de Fala com Whisper (OpenAI) 游"""

!pip install git+https://github.com/openai/whisper.git -q

import whisper

# Selecione o modelo do Whisper que melhor atenda 맙 suas necessidades:
# https://github.com/openai/whisper#available-models-and-languages
model = whisper.load_model("small")

# Transcreve o audio gravado anteriormente.
result = model.transcribe(record_file, fp16=False, language=language)
transcription = result['text']
print(transcription)

"""# 3. Integra칞칚o com a API do ChatGPT 游눫"""

!pip install --upgrade openai
!pip install groq

import os

# Documenta칞칚o Oficial da API OpenAI: https://platform.openai.com/docs/api-reference/introduction
# Informa칞칫es sobre o Per칤odo Gratuito: https://help.openai.com/en/articles/4936830

# Para gerar uma API Key:
# 1. Crie uma conta na OpenAI
# 2. Acesse a se칞칚o "API Keys"
# 3. Clique em "Create API Key"
# Link direto: https://platform.openai.com/account/api-keys

# Substitua o texto "TODO" por sua API Key da OpenAI, ela ser치 salva como uma vari치vel de ambiente.
os.environ['GROQ_API_KEY'] = 'GROQ_API_KEY'

import os
from openai import OpenAI

# client = OpenAI()

# # Configura a chave de API da OpenAI usando a vari치vel de ambiente 'OPENAI_API_KEY'
# #openai.api_key = os.environ.get('OPENAI_API_KEY')

# # Envia uma requisi칞칚o  API do ChatCompletion usando o modelo GPT-3.5 Turbo
# # Lembrando que, a vari치vel 'transcription' cont칠m a transcri칞칚o do nosso 치udio.
# response = client.chat.completions.create(
#     model="gpt-3.5-turbo",
#     messages=[ { "role": "user", "content": transcription } ]
# )

# # Obt칠m a resposta gerada pelo ChatGPT
# chatgpt_response = response.choices[0].message.content
# print(chatgpt_response)


client = OpenAI(
    base_url = 'https://api.groq.com/openai/v1',
    api_key = os.environ.get('GROQ_API_KEY')
)

response = client.chat.completions.create(
    model="openai/gpt-oss-120b", #modelo hospedado na Groq
    messages=[
        {"role": "user", "content": transcription}
    ]
)
print(response.choices[0].message.content)
chatgpt_response = response.choices[0].message.content

"""# 4. Sintetizando a Resposta do ChatGPT Como Voz (gTTS) 游댉"""

!pip install gTTS

from gtts import  gTTS

# Cria um objeto gTTS com a resposta gerada pelo ChatGPT e a l칤ngua que ser치 sintetizada em voz (vari치vel "language").
# gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)
gtts_object = gTTS(text=chatgpt_response, lang=language, slow=False)

# Salva o 치udio da resposta no arquivo especificado (pasta padr칚o do Google Colab)
response_audio = "/content/response_audio.wav"
gtts_object.save(response_audio)

# Reproduz o 치udio da resposta salvo no arquivo
display(Audio(response_audio, autoplay=True))